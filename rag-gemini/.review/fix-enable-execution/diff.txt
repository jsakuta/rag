diff --git a/rag-gemini/.codex/context/files.md b/rag-gemini/.codex/context/files.md
index 07302a6..98fec9e 100644
--- a/rag-gemini/.codex/context/files.md
+++ b/rag-gemini/.codex/context/files.md
@@ -1,207 +1,138 @@
 # é–¢é€£ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§
 
-## ä¸»è¦ä¿®æ­£å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«
+## 1. requirements.txt (ä¿®æ­£å¯¾è±¡)
 
-### 1. src/core/searcher.py (577è¡Œ)
-
-**å½¹å‰²**: ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ï¼ˆãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ + ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ï¼‰
-
-**ä¸»è¦ãªå•é¡Œç‚¹**:
-- æœªä½¿ç”¨ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆè¡Œ14: `ChatVertexAI`ï¼‰
-- æœªä½¿ç”¨å¤‰æ•°ï¼ˆè¡Œ47-49: `reference_vectors`, `reference_texts`, `reference_df`ï¼‰
-- æœªä½¿ç”¨ãƒ¡ã‚½ãƒƒãƒ‰ï¼ˆè¡Œ232-336: ã‚­ãƒ£ãƒƒã‚·ãƒ¥é–¢é€£4ãƒ¡ã‚½ãƒƒãƒ‰ï¼‰
-- ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰ï¼ˆè¡Œ76-77: Vertex AIè¨­å®šï¼‰
-- è¤‡é›‘ãªsearch()ãƒ¡ã‚½ãƒƒãƒ‰ï¼ˆç´„186è¡Œï¼‰
-- å‹ãƒ’ãƒ³ãƒˆäº’æ›æ€§ï¼ˆ`list[str]` â†’ `List[str]`ï¼‰
-
-**ä¿®æ­£ç®‡æ‰€**:
-```
-è¡Œ14: å‰Šé™¤ - from langchain_google_vertexai import ChatVertexAI
-è¡Œ47-49: å‰Šé™¤ - æœªä½¿ç”¨ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹å¤‰æ•°
-è¡Œ66-79: ä¿®æ­£ - èªè¨¼å‡¦ç†ã‚’auth.pyã«å§”è­²
-è¡Œ94, 109: ä¿®æ­£ - å‹ãƒ’ãƒ³ãƒˆ
-è¡Œ117: ä¿®æ­£ - position_weightå®šæ•°åŒ–
-è¡Œ232-336: å‰Šé™¤ - æœªä½¿ç”¨ãƒ¡ã‚½ãƒƒãƒ‰ç¾¤
-è¡Œ365-551: åˆ†å‰² - search()ãƒ¡ã‚½ãƒƒãƒ‰
-è¡Œ409: ä¿®æ­£ - VECTOR_SEARCH_MULTIPLIERå®šæ•°åŒ–
-è¡Œ506-514: ä¿®æ­£ - logger.info â†’ logger.debug
-```
-
----
-
-### 2. src/handlers/input_handler.py (428è¡Œ)
-
-**å½¹å‰²**: å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ï¼ˆExcel, éšå±¤æ§‹é€ Excel, è¤‡æ•°ãƒ•ã‚©ãƒ«ãƒ€å¯¾å¿œï¼‰
-
-**ä¸»è¦ãªå•é¡Œç‚¹**:
-- `_get_column_names()` ãŒExcelInputHandlerã¨MultiFolderInputHandlerã§é‡è¤‡
-- `_build_combined_text()` ç›¸å½“ã®ãƒ­ã‚¸ãƒƒã‚¯ãŒè¤‡æ•°ç®‡æ‰€ã§é‡è¤‡
-- å‹ãƒ’ãƒ³ãƒˆäº’æ›æ€§ï¼ˆ`tuple[str, str, str]` â†’ `Tuple[str, str, Optional[str]]`ï¼‰
-- ãƒã‚¸ãƒƒã‚¯ã‚¹ãƒˆãƒªãƒ³ã‚°ï¼ˆè¡Œ213: åŸå‰‡æ–‡åˆ¤å®šï¼‰
-
-**ä¿®æ­£ç®‡æ‰€**:
 ```
-è¡Œ7: ä¿®æ­£ - from typing import List, Tuple, Optional, Dict, Any
-è¡Œ23ä»˜è¿‘: è¿½åŠ  - åŸºåº•ã‚¯ãƒ©ã‚¹ã«_get_column_names(), _build_combined_text()
-è¡Œ138-147: å‰Šé™¤ - ExcelInputHandler._get_column_names()ï¼ˆåŸºåº•ã‚¯ãƒ©ã‚¹ä½¿ç”¨ï¼‰
-è¡Œ213: ä¿®æ­£ - PRINCIPLE_MARKERå®šæ•°åŒ–
-è¡Œ404-413: å‰Šé™¤ - MultiFolderInputHandler._get_column_names()ï¼ˆåŸºåº•ã‚¯ãƒ©ã‚¹ä½¿ç”¨ï¼‰
+pandas>=2.0.0
+numpy>=1.24.0
+sentence-transformers>=2.2.0
+scikit-learn>=1.3.0
+torch>=2.0.0
+# LangChainé–¢é€£ã‚’å‰Šé™¤ï¼ˆã‚¿ã‚°ãƒ¬ã‚¹å¯¾å¿œï¼‰
+# langchain>=0.1.0
+# langchain-anthropic>=0.0.1
+# langchain-openai>=0.0.1
+# langchain-google-genai>=0.0.1
+google-generativeai>=0.3.0
+google-cloud-aiplatform>=1.35.0
+google-auth>=2.17.0
+...
 ```
 
 ---
 
-### 3. src/utils/dynamic_db_manager.py (469è¡Œ)
+## 2. src/handlers/input_handler.py (ä¿®æ­£å¯¾è±¡)
 
-**å½¹å‰²**: æ¥­å‹™åˆ†é‡åˆ¥ã®å‹•çš„DBç®¡ç†
-
-**ä¸»è¦ãªå•é¡Œç‚¹**:
-- è£¸ã®except:ï¼ˆè¡Œ306ï¼‰
-- ãƒãƒƒãƒã‚µã‚¤ã‚ºãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰ï¼ˆè¡Œ335ï¼‰
-
-**ä¿®æ­£ç®‡æ‰€**:
-```
-è¡Œ306: ä¿®æ­£ - except: â†’ except chromadb.errors.InvalidCollectionException:
-è¡Œ335: ä¿®æ­£ - batch_size = 100 â†’ self.config.VECTOR_DB_BATCH_SIZE
-```
-
----
-
-### 4. config.py (98è¡Œ)
-
-**å½¹å‰²**: æ¤œç´¢è¨­å®šç®¡ç†ï¼ˆSearchConfigãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹ï¼‰
-
-**ä¿®æ­£å†…å®¹**: ãƒã‚¸ãƒƒã‚¯ãƒŠãƒ³ãƒãƒ¼ãƒ»ãƒã‚¸ãƒƒã‚¯ã‚¹ãƒˆãƒªãƒ³ã‚°ã®å®šæ•°è¿½åŠ 
-
-**è¿½åŠ ç®‡æ‰€** (è¡Œ30ä»˜è¿‘ã«è¿½åŠ ):
+### ExcelInputHandler.load_data() (Line 58-74)
 ```python
-# ãƒãƒƒãƒã‚µã‚¤ã‚ºè¨­å®š
-EMBEDDING_BATCH_SIZE: int = 5
-VECTOR_DB_BATCH_SIZE: int = 100
-
-# æ¤œç´¢è¨­å®š
-VECTOR_SEARCH_MULTIPLIER: int = 2
-POSITION_WEIGHT: float = 1.2
-
-# åˆ—åå€™è£œ
-QUERY_COLUMN_CANDIDATES: tuple = (...)
-ANSWER_COLUMN_CANDIDATES: tuple = (...)
-TAG_COLUMN_CANDIDATES: tuple = (...)
-
-# åŸå‰‡æ–‡åˆ¤å®šãƒãƒ¼ã‚«ãƒ¼
-PRINCIPLE_MARKER: str = "ä»¥ä¸‹ã®é¸æŠè‚¢ã‹ã‚‰é¸ã‚“ã§ãã ã•ã„"
+class ExcelInputHandler(InputHandler):
+    def load_data(self) -> list:
+        input_file = self._get_latest_file(self.input_dir, "*.xlsx")
+        logger.info(f"Processing input file: {os.path.basename(input_file)}")
+        input_df = pd.read_excel(input_file)
+
+        # åˆ—åãƒã‚§ãƒƒã‚¯ã¨ãƒ‡ãƒ¼ã‚¿æŠ½å‡º
+        number_col, query_col, answer_col = self._get_column_names(input_df)
+        valid_input_df = input_df.dropna(subset=[query_col])
+
+        data = []
+        for _, row in valid_input_df.iterrows():
+            data.append({
+                "number": str(row[number_col]),
+                "query": str(row[query_col]),
+                "answer": str(row[answer_col]) if answer_col and pd.notna(row[answer_col]) else ""
+            })
+        return data
+```
+
+### MultiFolderInputHandler.load_data() (Line 318-335)
+```python
+class MultiFolderInputHandler(InputHandler):
+    """è¤‡æ•°ãƒ•ã‚©ãƒ«ãƒ€ã‹ã‚‰å‚ç…§ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€ãƒãƒ³ãƒ‰ãƒ©ãƒ¼"""
+    
+    def load_data(self) -> list:
+        # å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ï¼ˆå¾“æ¥é€šã‚Šï¼‰
+        input_file = self._get_latest_file(self.input_dir, "*.xlsx")
+        logger.info(f"Processing input file: {os.path.basename(input_file)}")
+        input_df = pd.read_excel(input_file)
+
+        # åˆ—åãƒã‚§ãƒƒã‚¯ã¨ãƒ‡ãƒ¼ã‚¿æŠ½å‡º
+        number_col, query_col, answer_col = self._get_column_names(input_df)
+        valid_input_df = input_df.dropna(subset=[query_col])
+
+        data = []
+        for _, row in valid_input_df.iterrows():
+            data.append({
+                "number": str(row[number_col]),
+                "query": str(row[query_col]),
+                "answer": str(row[answer_col]) if answer_col and pd.notna(row[answer_col]) else ""
+            })
+        return data
 ```
 
 ---
 
-### 5. src/utils/gemini_embedding.py (104è¡Œ)
+## 3. src/core/processor.py (å‚ç…§å…ƒ)
 
-**å½¹å‰²**: Gemini Embedding APIã«ã‚ˆã‚‹ãƒ†ã‚­ã‚¹ãƒˆãƒ™ã‚¯ãƒˆãƒ«åŒ–
-
-**ä¸»è¦ãªå•é¡Œç‚¹**:
-- èªè¨¼å‡¦ç†ãŒé‡è¤‡ï¼ˆè¡Œ22-32: searcher.pyã¨åŒã˜å‡¦ç†ï¼‰
-- ãƒãƒƒãƒã‚µã‚¤ã‚ºãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰ï¼ˆè¡Œ61ï¼‰
+### Line 47ä»˜è¿‘
+```python
+# å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«åã‚’å–å¾—ï¼ˆå‹•çš„DBé¸æŠç”¨ï¼‰
+input_file = getattr(self.input_handler, 'current_file', None)
 
-**ä¿®æ­£ç®‡æ‰€**:
-```
-è¡Œ18-32: ä¿®æ­£ - èªè¨¼å‡¦ç†ã‚’auth.pyã«å§”è­²
-è¡Œ61: ä¿®æ­£ - batch_size = 5 â†’ self.config.EMBEDDING_BATCH_SIZE
+results = self.searcher.search(query_number, query_text, original_answer, input_file)
 ```
 
 ---
 
-### 6. src/utils/vector_db.py (149è¡Œ)
+## 4. src/core/searcher.py (ä¾å­˜é–¢ä¿‚)
 
-**å½¹å‰²**: ChromaDBãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ“ä½œ
-
-**ä¸»è¦ãªå•é¡Œç‚¹**:
-- ãƒãƒƒãƒã‚µã‚¤ã‚ºãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰ï¼ˆè¡Œ69ï¼‰
-- è£¸ã®except:ï¼ˆè¡Œ36ï¼‰
-
-**ä¿®æ­£ç®‡æ‰€**:
-```
-è¡Œ14: ä¿®æ­£ - ã‚³ãƒ³ã‚¹ãƒˆãƒ©ã‚¯ã‚¿ã«configå¼•æ•°è¿½åŠ 
-è¡Œ36: ä¿®æ­£ - except: â†’ å…·ä½“çš„ãªä¾‹å¤–å‹
-è¡Œ69: ä¿®æ­£ - batch_size = 100 â†’ self.config.VECTOR_DB_BATCH_SIZE
+### Line 12-16 (LangChain import)
+```python
+from langchain_anthropic import ChatAnthropic
+from langchain_openai import ChatOpenAI
+import vertexai
+from google.oauth2 import service_account
+from langchain.schema import HumanMessage, SystemMessage
 ```
 
 ---
 
-### 7. src/utils/logger.py (23è¡Œ)
-
-**å½¹å‰²**: ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
+## 5. src/utils/dynamic_db_manager.py (å‚ç…§)
 
-**ä¿®æ­£å†…å®¹**: ç’°å¢ƒå¤‰æ•°ã«ã‚ˆã‚‹ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«åˆ¶å¾¡ã€ãƒãƒ³ãƒ‰ãƒ©é‡è¤‡é˜²æ­¢
-
-**ä¿®æ­£å¾Œ**:
+### Line 28-29
 ```python
-def setup_logger(name):
-    logger = logging.getLogger(name)
-    log_level = os.getenv('LOG_LEVEL', 'INFO').upper()
-    logger.setLevel(getattr(logging, log_level, logging.INFO))
-    if logger.handlers:
-        return logger
-    # ... ãƒãƒ³ãƒ‰ãƒ©è¨­å®š
+self.reference_faq_path = os.path.join(config.base_dir, "reference", "faq_data")
+self.reference_scenario_path = os.path.join(config.base_dir, "reference", "scenario")
 ```
 
 ---
 
-## æ–°è¦ä½œæˆãƒ•ã‚¡ã‚¤ãƒ«
-
-### src/utils/auth.py (æ–°è¦)
+## 6. README.md (ä¿®æ­£å¯¾è±¡)
 
-**å½¹å‰²**: Google Cloudèªè¨¼å‡¦ç†ã®å…±é€šãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
+### ä¿®æ­£ãŒå¿…è¦ãªç®‡æ‰€
 
-**å†…å®¹**:
-```python
-def get_google_credentials(config): ...
-def initialize_vertex_ai(config, credentials=None): ...
+Line 118-120:
+```markdown
+#### ãƒãƒ¼ã‚¸ç‰ˆã‚·ãƒŠãƒªã‚ªï¼ˆéšå±¤æ§‹é€ Excelï¼‰
+- **é…ç½®å ´æ‰€**: `reference/ãƒãƒ¼ã‚¸ã‚·ãƒŠãƒªã‚ª/`
 ```
+â†’ `reference/scenario/` ã«å¤‰æ›´
 
----
-
-## ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ 
-
+Line 167-169:
+```markdown
+#### å±¥æ­´ãƒ‡ãƒ¼ã‚¿ï¼ˆå¾“æ¥å½¢å¼ï¼‰
+- **é…ç½®å ´æ‰€**: `reference/å±¥æ­´ãƒ‡ãƒ¼ã‚¿/`
 ```
-rag-gemini/
-â”œâ”€â”€ src/
-â”‚   â”œâ”€â”€ core/
-â”‚   â”‚   â”œâ”€â”€ processor.py      # å¤‰æ›´ãªã—
-â”‚   â”‚   â””â”€â”€ searcher.py       # ä¸»è¦ä¿®æ­£
-â”‚   â”œâ”€â”€ handlers/
-â”‚   â”‚   â”œâ”€â”€ input_handler.py  # ä¸»è¦ä¿®æ­£
-â”‚   â”‚   â””â”€â”€ output_handler.py # å¤‰æ›´ãªã—
-â”‚   â””â”€â”€ utils/
-â”‚       â”œâ”€â”€ auth.py           # æ–°è¦ä½œæˆ
-â”‚       â”œâ”€â”€ dynamic_db_manager.py # ä¿®æ­£
-â”‚       â”œâ”€â”€ gemini_embedding.py   # ä¿®æ­£
-â”‚       â”œâ”€â”€ logger.py         # ä¿®æ­£
-â”‚       â”œâ”€â”€ utils.py          # å¤‰æ›´ãªã—
-â”‚       â””â”€â”€ vector_db.py      # ä¿®æ­£
-â”œâ”€â”€ config.py                 # ä¿®æ­£ï¼ˆå®šæ•°è¿½åŠ ï¼‰
-â”œâ”€â”€ main.py                   # å¤‰æ›´ãªã—
-â”œâ”€â”€ backup/                   # ZIPã‚¢ãƒ¼ã‚«ã‚¤ãƒ–å¾Œå‰Šé™¤
-â””â”€â”€ old/                      # ZIPã‚¢ãƒ¼ã‚«ã‚¤ãƒ–å¾Œå‰Šé™¤
-```
-
----
-
-## ä¾å­˜é–¢ä¿‚
+â†’ `reference/faq_data/` ã«å¤‰æ›´
 
+Line 120:
+```markdown
+- **ãƒ™ã‚¯ãƒˆãƒ«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª**: `reference/vector_cache/`
 ```
-main.py
-â”œâ”€â”€ config.py (SearchConfig)
-â”œâ”€â”€ DynamicDBManager
-â”‚   â””â”€â”€ config.py
-â””â”€â”€ Processor
-    â”œâ”€â”€ InputHandlerFactory
-    â”‚   â”œâ”€â”€ ExcelInputHandler
-    â”‚   â”œâ”€â”€ HierarchicalExcelInputHandler
-    â”‚   â””â”€â”€ MultiFolderInputHandler
-    â”œâ”€â”€ OutputHandlerFactory
-    â””â”€â”€ Searcher
-        â”œâ”€â”€ auth.py (æ–°è¦) â† GeminiEmbeddingModel, _setup_llm()
-        â”œâ”€â”€ GeminiEmbeddingModel
-        â”‚   â””â”€â”€ auth.py (æ–°è¦)
-        â”œâ”€â”€ DynamicDBManager
-        â””â”€â”€ MetadataVectorDB
+â†’ `reference/vector_db/` ã«å¤‰æ›´
+
+Line 198-199:
+```markdown
+   streamlit run chat.py
 ```
+â†’ `streamlit run ui/chat.py` ã«å¤‰æ›´
diff --git a/rag-gemini/.codex/context/task.md b/rag-gemini/.codex/context/task.md
index c5e634b..88849de 100644
--- a/rag-gemini/.codex/context/task.md
+++ b/rag-gemini/.codex/context/task.md
@@ -1,485 +1,110 @@
-# ã‚¿ã‚¹ã‚¯: rag-gemini éæ©Ÿèƒ½æ”¹å–„ï¼ˆPhase 1-3ï¼‰
+# ã‚¿ã‚¹ã‚¯: rag-gemini å®Ÿè¡Œå¯èƒ½åŒ–ä¿®æ­£
 
 ## ç›®çš„
-rag-geminiãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ã‚³ãƒ¼ãƒ‰å“è³ªã€ä¿å®ˆæ€§ã€å¯èª­æ€§ã‚’å‘ä¸Šã•ã›ã‚‹éæ©Ÿèƒ½æ”¹å–„ã€‚æ©Ÿèƒ½ã¯ä¸€åˆ‡å¤‰æ›´ã›ãšã€ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°ã®ã¿å®Ÿæ–½ã™ã‚‹ã€‚
+rag-geminiãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’å®Ÿè¡Œå¯èƒ½ãªçŠ¶æ…‹ã«ã™ã‚‹ã€‚ç¾åœ¨ã€ä¾å­˜é–¢ä¿‚ã®ä¸æ•´åˆã¨DBé¸æŠãƒ­ã‚¸ãƒƒã‚¯ã®å•é¡Œã«ã‚ˆã‚Šå®Ÿè¡Œä¸å¯ã€‚
 
----
-
-## Phase 1: å³æ™‚å¯¾å¿œï¼ˆã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«ï¼‰
-
-### 1.1 ãƒ‡ãƒƒãƒ‰ã‚³ãƒ¼ãƒ‰ã®å‰Šé™¤
-
-#### å¤‰æ›´å¯¾è±¡: `src/core/searcher.py`
-
-**å‰Šé™¤é …ç›®1: æœªä½¿ç”¨ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆè¡Œ14ï¼‰**
-```python
-# å‰Šé™¤å¯¾è±¡
-from langchain_google_vertexai import ChatVertexAI
-```
-
-**å‰Šé™¤é …ç›®2: æœªä½¿ç”¨ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹å¤‰æ•°ï¼ˆè¡Œ47-49ï¼‰**
-```python
-# å‰Šé™¤å¯¾è±¡
-self.reference_vectors = None
-self.reference_texts = None
-self.reference_df = None # processor.pyã‹ã‚‰ç§»å‹•
-```
-
-**å‰Šé™¤é …ç›®3: æœªä½¿ç”¨ãƒ¡ã‚½ãƒƒãƒ‰ç¾¤ï¼ˆè¡Œ232-336ï¼‰**
-ä»¥ä¸‹ã®ãƒ¡ã‚½ãƒƒãƒ‰ã¯å‹•çš„DBç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ã§ä»£æ›¿ã•ã‚Œã¦ãŠã‚Šæœªä½¿ç”¨ã®ãŸã‚å‰Šé™¤ï¼š
-- `_is_data_unchanged()`ï¼ˆè¡Œ232-261ï¼‰
-- `_check_file_timestamps()`ï¼ˆè¡Œ263-296ï¼‰
-- `_get_file_timestamps()`ï¼ˆè¡Œ298-320ï¼‰
-- `_save_cache_info()`ï¼ˆè¡Œ322-336ï¼‰
-
-### 1.2 ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰ã®ä¿®æ­£
-
-#### å¤‰æ›´å¯¾è±¡: `src/core/searcher.py` è¡Œ75-78
-
-**ç¾åœ¨ã®ã‚³ãƒ¼ãƒ‰:**
-```python
-# Vertex AIåˆæœŸåŒ–
-vertexai.init(
-    project="pj-cbk001",
-    location="us-central1",
-    credentials=credentials
-)
-```
-
-**ä¿®æ­£å¾Œã®ã‚³ãƒ¼ãƒ‰:**
-```python
-# Vertex AIåˆæœŸåŒ–
-vertexai.init(
-    project=self.config.gemini_project_id,
-    location=self.config.gemini_location,
-    credentials=credentials
-)
-```
-
-### 1.3 ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°æ”¹å–„
-
-#### å¤‰æ›´å¯¾è±¡: `src/utils/dynamic_db_manager.py` è¡Œ306
-
-**ç¾åœ¨ã®ã‚³ãƒ¼ãƒ‰:**
-```python
-except:
-    logger.info(f"ChromaDBã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã¯å­˜åœ¨ã—ã¾ã›ã‚“: {collection_name}")
-```
-
-**ä¿®æ­£å¾Œã®ã‚³ãƒ¼ãƒ‰:**
-```python
-except chromadb.errors.InvalidCollectionException:
-    logger.info(f"ChromaDBã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã¯å­˜åœ¨ã—ã¾ã›ã‚“: {collection_name}")
-```
+## å®Ÿè£…è¦ä»¶
+1. requirements.txtã®LangChainé–¢é€£ã‚³ãƒ¡ãƒ³ãƒˆã‚’è§£é™¤ã—ã¦ä¾å­˜é–¢ä¿‚ã‚’æœ‰åŠ¹åŒ–
+2. input_handler.pyã®å„InputHandlerã‚¯ãƒ©ã‚¹ã«current_fileå±æ€§ã‚’è¿½åŠ 
+3. reference/scenario/ãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆ
+4. README.mdã®ãƒ‘ã‚¹åã¨ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿã‚³ãƒ¼ãƒ‰ã«åˆã‚ã›ã¦ä¿®æ­£
 
 ---
 
-## Phase 2: çŸ­æœŸå¯¾å¿œ
-
-### 2.1 Googleèªè¨¼å‡¦ç†ã®å…±é€šåŒ–
-
-#### æ–°è¦ä½œæˆ: `src/utils/auth.py`
-
-```python
-"""Google Cloudèªè¨¼å‡¦ç†ã®å…±é€šãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«"""
-import os
-import vertexai
-from google.oauth2 import service_account
-from src.utils.logger import setup_logger
-
-logger = setup_logger(__name__)
-
-
-def get_google_credentials(config):
-    """Google Cloudèªè¨¼æƒ…å ±ã‚’å–å¾—
-
-    Args:
-        config: SearchConfig ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
+## å¤‰æ›´å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«
 
-    Returns:
-        service_account.Credentials: èªè¨¼æƒ…å ±
-    """
-    credentials_path = os.path.join(config.base_dir, config.gemini_credentials_path)
-    return service_account.Credentials.from_service_account_file(
-        credentials_path,
-        scopes=['https://www.googleapis.com/auth/cloud-platform']
-    )
+### 1. requirements.txt
+**å¤‰æ›´å†…å®¹**: Line 6-10ã®ã‚³ãƒ¡ãƒ³ãƒˆã‚’è§£é™¤ã—ã¦LangChainä¾å­˜é–¢ä¿‚ã‚’æœ‰åŠ¹åŒ–
 
-
-def initialize_vertex_ai(config, credentials=None):
-    """Vertex AIã‚’åˆæœŸåŒ–
-
-    Args:
-        config: SearchConfig ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
-        credentials: èªè¨¼æƒ…å ±ï¼ˆçœç•¥æ™‚ã¯è‡ªå‹•å–å¾—ï¼‰
-    """
-    if credentials is None:
-        credentials = get_google_credentials(config)
-
-    vertexai.init(
-        project=config.gemini_project_id,
-        location=config.gemini_location,
-        credentials=credentials
-    )
-    logger.info("Vertex AI initialized successfully")
+**ç¾åœ¨ã®ã‚³ãƒ¼ãƒ‰**:
 ```
-
-#### ä¿®æ­£å¯¾è±¡: `src/core/searcher.py` è¡Œ66-79
-
-**ç¾åœ¨ã®ã‚³ãƒ¼ãƒ‰:**
-```python
-elif self.config.llm_provider == "gemini":
-    # Vertex AI Geminiç”¨ã®èªè¨¼è¨­å®š
-    try:
-        # èªè¨¼æƒ…å ±ã‚’èª­ã¿è¾¼ã¿
-        credentials = service_account.Credentials.from_service_account_file(
-            os.path.join(self.config.base_dir, "gemini_credentials.json"),
-            scopes=['https://www.googleapis.com/auth/cloud-platform']
-        )
-
-        # Vertex AIåˆæœŸåŒ–
-        vertexai.init(
-            project=self.config.gemini_project_id,
-            location=self.config.gemini_location,
-            credentials=credentials
-        )
-```
-
-**ä¿®æ­£å¾Œã®ã‚³ãƒ¼ãƒ‰:**
-```python
-elif self.config.llm_provider == "gemini":
-    # Vertex AI Geminiç”¨ã®èªè¨¼è¨­å®š
-    try:
-        from src.utils.auth import get_google_credentials, initialize_vertex_ai
-        credentials = get_google_credentials(self.config)
-        initialize_vertex_ai(self.config, credentials)
+# LangChainé–¢é€£ã‚’å‰Šé™¤ï¼ˆã‚¿ã‚°ãƒ¬ã‚¹å¯¾å¿œï¼‰
+# langchain>=0.1.0
+# langchain-anthropic>=0.0.1
+# langchain-openai>=0.0.1
+# langchain-google-genai>=0.0.1
 ```
 
-#### ä¿®æ­£å¯¾è±¡: `src/utils/gemini_embedding.py` è¡Œ18-32
-
-**ç¾åœ¨ã®ã‚³ãƒ¼ãƒ‰:**
-```python
-def _setup_model(self):
-    """Gemini Embedding APIã®åˆæœŸåŒ–"""
-    try:
-        # èªè¨¼æƒ…å ±ã‚’èª­ã¿è¾¼ã¿
-        credentials = service_account.Credentials.from_service_account_file(
-            os.path.join(self.config.base_dir, "gemini_credentials.json"),
-            scopes=['https://www.googleapis.com/auth/cloud-platform']
-        )
-
-        # Vertex AIåˆæœŸåŒ–
-        vertexai.init(
-            project=self.config.gemini_project_id,
-            location=self.config.gemini_location,
-            credentials=credentials
-        )
+**å®Ÿè£…ã™ã¹ãã‚³ãƒ¼ãƒ‰**:
 ```
-
-**ä¿®æ­£å¾Œã®ã‚³ãƒ¼ãƒ‰:**
-```python
-def _setup_model(self):
-    """Gemini Embedding APIã®åˆæœŸåŒ–"""
-    try:
-        from src.utils.auth import initialize_vertex_ai
-        initialize_vertex_ai(self.config)
+# LangChainé–¢é€£ï¼ˆLLMæ‹¡å¼µæ¤œç´¢æ©Ÿèƒ½ç”¨ï¼‰
+langchain>=0.1.0
+langchain-anthropic>=0.0.1
+langchain-openai>=0.0.1
+langchain-google-genai>=0.0.1
 ```
 
-### 2.2 ã‚³ãƒ¼ãƒ‰é‡è¤‡è§£æ¶ˆï¼ˆinput_handler.pyï¼‰
-
-#### ä¿®æ­£å¯¾è±¡: åŸºåº•ã‚¯ãƒ©ã‚¹ `InputHandler` ã«å…±é€šãƒ¡ã‚½ãƒƒãƒ‰ã‚’è¿½åŠ 
-
-**è¿½åŠ ã™ã‚‹ãƒ¡ã‚½ãƒƒãƒ‰ï¼ˆè¡Œ23ä»˜è¿‘ã«è¿½åŠ ï¼‰:**
-```python
-def _get_column_names(self, df: pd.DataFrame) -> Tuple[str, str, Optional[str]]:
-    """Excelãƒ•ã‚¡ã‚¤ãƒ«ã®åˆ—åã‚’å–å¾—ãƒ»æ¤œè¨¼"""
-    if len(df.columns) < 2:
-        raise ValueError("Input file must have at least 2 columns (Number and Query)")
-
-    number_col = df.columns[0]
-    query_col = df.columns[1]
-    answer_col = df.columns[2] if len(df.columns) > 2 else None
-    logger.info(f"Using columns: Number='{number_col}', Query='{query_col}', Answer='{answer_col}'")
-    return number_col, query_col, answer_col
-
-def _build_combined_text(self, hierarchy: str, query: str, answer: str) -> str:
-    """çµåˆãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆ"""
-    text_parts = []
-    if hierarchy and hierarchy.strip():
-        text_parts.append(f"åˆ†é¡: {hierarchy}")
-    if query and query.strip():
-        text_parts.append(f"è³ªå•: {query}")
-    if answer and answer.strip():
-        text_parts.append(f"å›ç­”: {answer}")
-    return " | ".join(text_parts) if text_parts else ""
-```
-
-**å‰Šé™¤å¯¾è±¡:**
-- `ExcelInputHandler._get_column_names()` (è¡Œ138-147) - åŸºåº•ã‚¯ãƒ©ã‚¹ã‚’ä½¿ç”¨
-- `MultiFolderInputHandler._get_column_names()` (è¡Œ404-413) - åŸºåº•ã‚¯ãƒ©ã‚¹ã‚’ä½¿ç”¨
-
-### 2.3 ãƒã‚¸ãƒƒã‚¯ãƒŠãƒ³ãƒãƒ¼å®šæ•°åŒ–
-
-#### ä¿®æ­£å¯¾è±¡: `config.py` ã«å®šæ•°è¿½åŠ ï¼ˆè¡Œ30ä»˜è¿‘ï¼‰
-
-```python
-# ãƒãƒƒãƒã‚µã‚¤ã‚ºè¨­å®š
-EMBEDDING_BATCH_SIZE: int = 5
-VECTOR_DB_BATCH_SIZE: int = 100
-
-# æ¤œç´¢è¨­å®š
-VECTOR_SEARCH_MULTIPLIER: int = 2
-POSITION_WEIGHT: float = 1.2
-
-# åˆ—åå€™è£œ
-QUERY_COLUMN_CANDIDATES: tuple = ('åˆ†å‰²å¾Œè³ªå•', 'å•åˆã›å†…å®¹', 'è³ªå•å†…å®¹', 'å•ã„åˆã‚ã›', 'è³ªå•', 'query', 'Query')
-ANSWER_COLUMN_CANDIDATES: tuple = ('åˆ†å‰²å¾Œå›ç­”', 'å›ç­”', 'æ—¢å­˜å›ç­”', 'answer', 'Answer')
-TAG_COLUMN_CANDIDATES: tuple = ('ã‚¿ã‚°ä»˜ã‘', 'ã‚¿ã‚°', 'åˆ†é¡', 'category', 'Category', 'tag', 'Tag')
-
-# åŸå‰‡æ–‡åˆ¤å®šãƒãƒ¼ã‚«ãƒ¼
-PRINCIPLE_MARKER: str = "ä»¥ä¸‹ã®é¸æŠè‚¢ã‹ã‚‰é¸ã‚“ã§ãã ã•ã„"
-```
-
-#### å„ãƒ•ã‚¡ã‚¤ãƒ«ã§ã®å®šæ•°å‚ç…§
-
-**gemini_embedding.py è¡Œ61:**
-```python
-# Before
-batch_size = 5
-
-# After
-batch_size = self.config.EMBEDDING_BATCH_SIZE
-```
-
-**vector_db.py è¡Œ69:**
-```python
-# Before
-batch_size = 100
-
-# Afterï¼ˆã‚³ãƒ³ã‚¹ãƒˆãƒ©ã‚¯ã‚¿ã«configã‚’æ¸¡ã™æ–¹å¼ã«å¤‰æ›´ï¼‰
-# __init__ã§configã‚’å—ã‘å–ã‚Šã€self.config.VECTOR_DB_BATCH_SIZEã‚’ä½¿ç”¨
-```
-
-**searcher.py è¡Œ117:**
-```python
-# Before
-position_weight = 1.2
-
-# After
-position_weight = self.config.POSITION_WEIGHT
-```
-
-**searcher.py è¡Œ409:**
-```python
-# Before
-n_results=self.config.top_k * 2
-
-# After
-n_results=self.config.top_k * self.config.VECTOR_SEARCH_MULTIPLIER
-```
-
-**input_handler.py è¡Œ213:**
-```python
-# Before
-is_principle = "ä»¥ä¸‹ã®é¸æŠè‚¢ã‹ã‚‰é¸ã‚“ã§ãã ã•ã„" in answer
-
-# After
-is_principle = self.config.PRINCIPLE_MARKER in answer
-```
-
-### 2.4 ãƒ­ã‚®ãƒ³ã‚°æœ€é©åŒ–
-
-#### ä¿®æ­£å¯¾è±¡: `src/utils/logger.py`
-
-**ä¿®æ­£å¾Œã®ã‚³ãƒ¼ãƒ‰ï¼ˆå…¨ä½“ç½®æ›ï¼‰:**
-```python
-# --- utils/logger.py ---
-import logging
-import os
-
-
-def setup_logger(name):
-    """ãƒ­ã‚¬ãƒ¼ã®è¨­å®š"""
-    logger = logging.getLogger(name)
-
-    # ç’°å¢ƒå¤‰æ•°ã§ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«ã‚’åˆ¶å¾¡
-    log_level = os.getenv('LOG_LEVEL', 'INFO').upper()
-    logger.setLevel(getattr(logging, log_level, logging.INFO))
-
-    # ãƒãƒ³ãƒ‰ãƒ©ã®é‡è¤‡è¿½åŠ ã‚’é˜²æ­¢
-    if logger.handlers:
-        return logger
-
-    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(name)s - %(message)s')
-
-    log_dir = "logs"
-    os.makedirs(log_dir, exist_ok=True)
-    log_file = os.path.join(log_dir, 'app.log')
-
-    file_handler = logging.FileHandler(log_file, encoding='utf-8')
-    file_handler.setFormatter(formatter)
-
-    stream_handler = logging.StreamHandler()
-    stream_handler.setFormatter(formatter)
-
-    logger.addHandler(file_handler)
-    logger.addHandler(stream_handler)
-    return logger
-```
-
-#### ä¿®æ­£å¯¾è±¡: `src/core/searcher.py` - è©³ç´°ãƒ­ã‚°ã‚’debugãƒ¬ãƒ™ãƒ«ã«å¤‰æ›´
-
-**è¡Œ506-514 ã®è©³ç´°ãƒ­ã‚°ã‚’debugã«å¤‰æ›´:**
-```python
-# Before
-logger.info(f"  ã€çµæœ{i+1}ã€‘(i={i})")
-logger.info(f"    Input_Number: {result_data['Input_Number']}")
-...
-
-# After
-logger.debug(f"  ã€çµæœ{i+1}ã€‘(i={i})")
-logger.debug(f"    Input_Number: {result_data['Input_Number']}")
-...
-```
-
-### 2.5 å‹ãƒ’ãƒ³ãƒˆçµ±ä¸€
+---
 
-#### ä¿®æ­£å¯¾è±¡: `src/core/searcher.py`
+### 2. src/handlers/input_handler.py
+**å¤‰æ›´å†…å®¹**: ExcelInputHandlerã¨MultiFolderInputHandlerã®load_data()ãƒ¡ã‚½ãƒƒãƒ‰ã§self.current_fileã‚’è¨­å®š
 
-**è¡Œ94:**
+**ExcelInputHandler.load_data() - ç¾åœ¨ã®ã‚³ãƒ¼ãƒ‰** (Line 58-74):
 ```python
-# Before
-def _extract_keywords(self, text: str, top_k: int = 5) -> list[str]:
-
-# After
-def _extract_keywords(self, text: str, top_k: int = 5) -> List[str]:
+def load_data(self) -> list:
+    input_file = self._get_latest_file(self.input_dir, "*.xlsx")
+    logger.info(f"Processing input file: {os.path.basename(input_file)}")
+    input_df = pd.read_excel(input_file)
 ```
 
-**è¡Œ109:**
+**ExcelInputHandler.load_data() - å®Ÿè£…ã™ã¹ãã‚³ãƒ¼ãƒ‰**:
 ```python
-# Before
-def _calculate_keyword_similarity(self, query_keywords: list[str], reference_text: str) -> float:
-
-# After
-def _calculate_keyword_similarity(self, query_keywords: List[str], reference_text: str) -> float:
+def load_data(self) -> list:
+    input_file = self._get_latest_file(self.input_dir, "*.xlsx")
+    self.current_file = os.path.basename(input_file)  # è¿½åŠ : DBé¸æŠç”¨
+    logger.info(f"Processing input file: {self.current_file}")
+    input_df = pd.read_excel(input_file)
 ```
 
-#### ä¿®æ­£å¯¾è±¡: `src/handlers/input_handler.py`
-
-**è¡Œ7:**
+**MultiFolderInputHandler.load_data() - ç¾åœ¨ã®ã‚³ãƒ¼ãƒ‰** (Line 318-335):
 ```python
-# Before
-from typing import List
-
-# After
-from typing import List, Tuple, Optional, Dict, Any
+def load_data(self) -> list:
+    input_file = self._get_latest_file(self.input_dir, "*.xlsx")
+    logger.info(f"Processing input file: {os.path.basename(input_file)}")
+    input_df = pd.read_excel(input_file)
 ```
 
-**è¡Œ138, 404:**
+**MultiFolderInputHandler.load_data() - å®Ÿè£…ã™ã¹ãã‚³ãƒ¼ãƒ‰**:
 ```python
-# Before
-def _get_column_names(self, df: pd.DataFrame) -> tuple[str, str, str]:
-
-# After (åŸºåº•ã‚¯ãƒ©ã‚¹ã«ç§»å‹•å¾Œ)
-def _get_column_names(self, df: pd.DataFrame) -> Tuple[str, str, Optional[str]]:
+def load_data(self) -> list:
+    input_file = self._get_latest_file(self.input_dir, "*.xlsx")
+    self.current_file = os.path.basename(input_file)  # è¿½åŠ : DBé¸æŠç”¨
+    logger.info(f"Processing input file: {self.current_file}")
+    input_df = pd.read_excel(input_file)
 ```
 
 ---
 
-## Phase 3: ä¸­æœŸå¯¾å¿œ
-
-### 3.1 search()ãƒ¡ã‚½ãƒƒãƒ‰åˆ†å‰²
-
-#### å¤‰æ›´å¯¾è±¡: `src/core/searcher.py`
-
-ç¾çŠ¶ã®`search()`ãƒ¡ã‚½ãƒƒãƒ‰ï¼ˆç´„186è¡Œï¼‰ã‚’ä»¥ä¸‹ã®ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆãƒ¡ã‚½ãƒƒãƒ‰ã«åˆ†å‰²ï¼š
-
-```python
-def search(self, input_number: str, query_text: str, original_answer: str, input_file: str = None) -> List[Dict[str, Any]]:
-    """ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å¯¾å¿œãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ã‚’å®Ÿè¡Œ"""
-    self._select_db_if_needed(input_file)
-    search_query, query_for_vector = self._prepare_search_query(query_text)
-    keywords = self._extract_keywords(query_text)
-    search_results = self._execute_vector_search(query_for_vector)
-    results = self._calculate_and_merge_scores(search_results, keywords)
-    return self._format_final_results(results, input_number, query_text, original_answer, search_query)
-
-
-def _select_db_if_needed(self, input_file: Optional[str]) -> None:
-    """å‹•çš„DBé¸æŠï¼ˆå…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆï¼‰"""
-    # è¡Œ368-376 ã®ãƒ­ã‚¸ãƒƒã‚¯ã‚’ç§»å‹•
-
-
-def _prepare_search_query(self, query_text: str) -> Tuple[str, str]:
-    """æ¤œç´¢ã‚¯ã‚¨ãƒªã®ç”Ÿæˆï¼ˆæ¤œç´¢æ–¹å¼ã«ã‚ˆã‚‹åˆ†å²ï¼‰"""
-    # è¡Œ386-396 ã®ãƒ­ã‚¸ãƒƒã‚¯ã‚’ç§»å‹•
-
+### 3. reference/scenario/ ãƒ•ã‚©ãƒ«ãƒ€
+**å¤‰æ›´å†…å®¹**: ç©ºã®ãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆï¼ˆå°†æ¥ã®ã‚·ãƒŠãƒªã‚ªãƒ‡ãƒ¼ã‚¿ç”¨ï¼‰
 
-def _execute_vector_search(self, query_for_vector: str) -> List[Dict[str, Any]]:
-    """ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã‚’å®Ÿè¡Œ"""
-    # è¡Œ405-419 ã®ãƒ­ã‚¸ãƒƒã‚¯ã‚’ç§»å‹•
-
-
-def _calculate_and_merge_scores(self, search_results: List[Dict[str, Any]], keywords: List[str]) -> List[Dict[str, Any]]:
-    """ã‚¹ã‚³ã‚¢è¨ˆç®—ã¨çµæœçµ±åˆ"""
-    # è¡Œ435-516 ã®ãƒ­ã‚¸ãƒƒã‚¯ã‚’ç§»å‹•
-
-
-def _format_final_results(self, results: List[Dict[str, Any]], input_number: str, query_text: str, original_answer: str, search_query: str) -> List[Dict[str, Any]]:
-    """çµæœã®æ•´å½¢ã¨ã‚½ãƒ¼ãƒˆ"""
-    # è¡Œ529-551 ã®ãƒ­ã‚¸ãƒƒã‚¯ã‚’ç§»å‹•
-```
-
-### 3.2 ä¾å­˜æ€§æ³¨å…¥å°å…¥
-
-#### å¤‰æ›´å¯¾è±¡: `src/core/searcher.py` ã® `__init__` ãƒ¡ã‚½ãƒƒãƒ‰
-
-**ä¿®æ­£å¾Œã®ã‚³ãƒ¼ãƒ‰:**
-```python
-def __init__(self, config: SearchConfig,
-             db_manager: Optional[DynamicDBManager] = None,
-             embedding_model: Optional['GeminiEmbeddingModel'] = None):
-    self.config = config
-    self.tokenizer = Dictionary().create()
-    self.mode = tokenizer.Tokenizer.SplitMode.C
-
-    # ä¾å­˜æ€§æ³¨å…¥: å¤–éƒ¨ã‹ã‚‰æ³¨å…¥ã•ã‚Œãªã„å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚’ç”Ÿæˆ
-    if embedding_model is None:
-        from src.utils.gemini_embedding import GeminiEmbeddingModel
-        embedding_model = GeminiEmbeddingModel(config)
-    self.model = embedding_model
+---
 
-    self.db_manager = db_manager or DynamicDBManager(config)
-    self.current_db_path = None
-    self.current_business_area = None
-    logger.info("å‹•çš„DBç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ã‚’åˆæœŸåŒ–ã—ã¾ã—ãŸ")
+### 4. README.md
+**å¤‰æ›´å†…å®¹**: ãƒ‘ã‚¹åã¨ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿã‚³ãƒ¼ãƒ‰ã«åˆã‚ã›ã¦æ›´æ–°
 
-    # LLMåˆæœŸåŒ–ï¼ˆæ¡ä»¶ä»˜ãï¼‰
-    if self.config.search_mode == "llm_enhanced" and self.config.enable_query_enhancement:
-        self.llm = self._setup_llm()
-        logger.info("LLM initialized for enhanced search mode")
-    else:
-        self.llm = None
-        logger.info("LLM not initialized - using original search mode")
-```
+| å¤‰æ›´å‰ | å¤‰æ›´å¾Œ |
+|--------|--------|
+| reference/ãƒãƒ¼ã‚¸ã‚·ãƒŠãƒªã‚ª/ | reference/scenario/ |
+| reference/å±¥æ­´ãƒ‡ãƒ¼ã‚¿/ | reference/faq_data/ |
+| reference/vector_cache/ | reference/vector_db/ |
+| streamlit run chat.py | streamlit run ui/chat.py |
 
-### 3.3 ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«æ•´ç†
+---
 
-1. `backup/` ãƒ•ã‚©ãƒ«ãƒ€ã‚’ZIPã‚¢ãƒ¼ã‚«ã‚¤ãƒ–
-2. `old/` ãƒ•ã‚©ãƒ«ãƒ€ã‚’ZIPã‚¢ãƒ¼ã‚«ã‚¤ãƒ–
-3. `.gitignore` ã«è¿½åŠ :
-```
-backup/
-old/
-*.bak
-```
+## ä¾å­˜é–¢ä¿‚
+- searcher.py: LangChainã®ChatAnthropic, ChatOpenAIã‚’importï¼ˆLine 12-16ï¼‰
+- processor.py: input_handler.current_fileã‚’å‚ç…§ï¼ˆLine 47ï¼‰
+- dynamic_db_manager.py: reference/scenario, reference/faq_dataã‚’å‚ç…§ï¼ˆLine 28-29ï¼‰
 
----
+## åˆ¶ç´„
+- æ—¢å­˜ã®å‹•ä½œã‚’å£Šã•ãªã„ã“ã¨
+- LLMæ‹¡å¼µæ¤œç´¢ã¯config.pyã§search_mode="llm_enhanced"ã®æ™‚ã®ã¿ä½¿ç”¨
 
 ## å®Œäº†æ¡ä»¶
-
-- [ ] Phase 1: ãƒ‡ãƒƒãƒ‰ã‚³ãƒ¼ãƒ‰å‰Šé™¤ã€ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰ä¿®æ­£ã€ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°æ”¹å–„
-- [ ] Phase 2: èªè¨¼å‡¦ç†å…±é€šåŒ–ã€ã‚³ãƒ¼ãƒ‰é‡è¤‡è§£æ¶ˆã€å®šæ•°åŒ–ã€ãƒ­ã‚°æœ€é©åŒ–ã€å‹ãƒ’ãƒ³ãƒˆçµ±ä¸€
-- [ ] Phase 3: search()åˆ†å‰²ã€ä¾å­˜æ€§æ³¨å…¥ã€ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æ•´ç†
-- [ ] Pythonã‚¨ãƒ©ãƒ¼ãŒãªã„ï¼ˆ`python -m py_compile`ï¼‰
-- [ ] æ—¢å­˜æ©Ÿèƒ½ãŒæ­£å¸¸å‹•ä½œ
+- [ ] requirements.txtã®LangChainä¾å­˜é–¢ä¿‚ãŒæœ‰åŠ¹åŒ–ã•ã‚Œã¦ã„ã‚‹
+- [ ] ExcelInputHandler.load_data()ã§self.current_fileãŒè¨­å®šã•ã‚Œã‚‹
+- [ ] MultiFolderInputHandler.load_data()ã§self.current_fileãŒè¨­å®šã•ã‚Œã‚‹
+- [ ] reference/scenario/ãƒ•ã‚©ãƒ«ãƒ€ãŒå­˜åœ¨ã™ã‚‹
+- [ ] README.mdã®ãƒ‘ã‚¹åãŒå®Ÿã‚³ãƒ¼ãƒ‰ã¨ä¸€è‡´ã—ã¦ã„ã‚‹
+- [ ] pip install -r requirements.txtãŒæˆåŠŸã™ã‚‹
diff --git a/rag-gemini/README.md b/rag-gemini/README.md
index d35cf0f..a090453 100644
--- a/rag-gemini/README.md
+++ b/rag-gemini/README.md
@@ -115,9 +115,9 @@ pip install -r requirements.txt
 | --- | --- | --- |
 | ğŸ“ input/ | å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ç”¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª | è³ªå•ãƒ‡ãƒ¼ã‚¿ã‚’å«ã‚€Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’é…ç½® |
 | ğŸ“ reference/ | å‚ç…§ãƒ‡ãƒ¼ã‚¿ç”¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª | æ¤œç´¢å¯¾è±¡ã¨ãªã‚‹å‚ç…§ç”¨Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’é…ç½® |
-| ğŸ“ reference/ãƒãƒ¼ã‚¸ã‚·ãƒŠãƒªã‚ª/ | ãƒãƒ¼ã‚¸ç‰ˆã‚·ãƒŠãƒªã‚ªç”¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª | éšå±¤æ§‹é€ ã‚’æŒã¤Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’é…ç½® |
-| ğŸ“ reference/å±¥æ­´ãƒ‡ãƒ¼ã‚¿/ | å±¥æ­´ãƒ‡ãƒ¼ã‚¿ç”¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª | å¾“æ¥ã®å•åˆã›å±¥æ­´ãƒ‡ãƒ¼ã‚¿ã‚’é…ç½® |
-| ğŸ“ reference/vector_cache/ | ãƒ™ã‚¯ãƒˆãƒ«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª | è¨ˆç®—æ¸ˆã¿ã®å‚ç…§ãƒ‡ãƒ¼ã‚¿ã®ãƒ™ã‚¯ãƒˆãƒ«ã‚’JSONå½¢å¼ã§ä¿å­˜ |
+| ğŸ“ reference/scenario/ | ãƒãƒ¼ã‚¸ç‰ˆã‚·ãƒŠãƒªã‚ªç”¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª | éšå±¤æ§‹é€ ã‚’æŒã¤Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’é…ç½® |
+| ğŸ“ reference/faq_data/ | å±¥æ­´ãƒ‡ãƒ¼ã‚¿ç”¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª | å¾“æ¥ã®å•åˆã›å±¥æ­´ãƒ‡ãƒ¼ã‚¿ã‚’é…ç½® |
+| ğŸ“ reference/vector_db/ | ãƒ™ã‚¯ãƒˆãƒ«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª | è¨ˆç®—æ¸ˆã¿ã®å‚ç…§ãƒ‡ãƒ¼ã‚¿ã®ãƒ™ã‚¯ãƒˆãƒ«ã‚’JSONå½¢å¼ã§ä¿å­˜ |
 | ğŸ“ prompt/ | ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª | LLMç”¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ« (.txt) ã‚’ä¿å­˜ |
 | ğŸ“ output/ | å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ç”¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª | æ¤œç´¢çµæœã®Excelãƒ•ã‚¡ã‚¤ãƒ«ãŒå‡ºåŠ›ã•ã‚Œã‚‹ |
 | ğŸ“ logs/ | ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ç”¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª | ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ­ã‚° (app.log) ã®ä¿å­˜å…ˆ |
@@ -157,14 +157,14 @@ OPENAI_API_KEY=your_openai_api_key
 ### 3.2 å‚ç…§ãƒ‡ãƒ¼ã‚¿ã®é…ç½®
 
 #### ãƒãƒ¼ã‚¸ç‰ˆã‚·ãƒŠãƒªã‚ªï¼ˆéšå±¤æ§‹é€ Excelï¼‰
-- **é…ç½®å ´æ‰€**: `reference/ãƒãƒ¼ã‚¸ã‚·ãƒŠãƒªã‚ª/`
+- **é…ç½®å ´æ‰€**: `reference/scenario/`
 - **ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼**: Excel (.xlsx)
 - **æ§‹é€ **: Lv1, Lv2, Lv3... ã®éšå±¤åˆ—
 - **å‡¦ç†**: å…¨ã‚·ãƒ¼ãƒˆã‚’è‡ªå‹•å‡¦ç†
 - **ç‰¹å¾´**: åŸå‰‡æ–‡ã¨é€šå¸¸ã®å•ç­”ã‚’è‡ªå‹•åˆ¤åˆ¥
 
 #### å±¥æ­´ãƒ‡ãƒ¼ã‚¿ï¼ˆå¾“æ¥å½¢å¼ï¼‰
-- **é…ç½®å ´æ‰€**: `reference/å±¥æ­´ãƒ‡ãƒ¼ã‚¿/`
+- **é…ç½®å ´æ‰€**: `reference/faq_data/`
 - **ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼**: Excel (.xlsx)
 - **å¿…é ˆåˆ—**: å•åˆã›å†…å®¹ã€å›ç­”
 - **å‡¦ç†**: å¾“æ¥é€šã‚Šã®å½¢å¼ã§å‡¦ç†
@@ -178,8 +178,8 @@ OPENAI_API_KEY=your_openai_api_key
 1. å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã®é…ç½®
    - è³ªå•ãƒ‡ãƒ¼ã‚¿ã‚’ `input/` ã«é…ç½®
 2. å‚ç…§ãƒ‡ãƒ¼ã‚¿ã®é…ç½®
-   - ãƒãƒ¼ã‚¸ç‰ˆã‚·ãƒŠãƒªã‚ªã‚’ `reference/ãƒãƒ¼ã‚¸ã‚·ãƒŠãƒªã‚ª/` ã«é…ç½®
-   - å±¥æ­´ãƒ‡ãƒ¼ã‚¿ã‚’ `reference/å±¥æ­´ãƒ‡ãƒ¼ã‚¿/` ã«é…ç½®
+   - ãƒãƒ¼ã‚¸ç‰ˆã‚·ãƒŠãƒªã‚ªã‚’ `reference/scenario/` ã«é…ç½®
+   - å±¥æ­´ãƒ‡ãƒ¼ã‚¿ã‚’ `reference/faq_data/` ã«é…ç½®
 3. è¨­å®šç¢ºèª
    - `config.py` ã§ `reference_type: "multi_folder"` ã‚’ç¢ºèª
 4. ã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œ
@@ -195,7 +195,7 @@ OPENAI_API_KEY=your_openai_api_key
    ```bash
    python main.py interactive
    # ã¾ãŸã¯
-   streamlit run chat.py
+   streamlit run ui/chat.py
    ```
 2. Web UIæ“ä½œ
    - è³ªå•ã‚’å…¥åŠ›ã—ã€Œé€ä¿¡ã€ã‚’ã‚¯ãƒªãƒƒã‚¯
@@ -488,8 +488,8 @@ pip install -r requirements.txt
 
 ã‚­ãƒ£ãƒƒã‚·ãƒ¥é–¢é€£ã®ã‚¨ãƒ©ãƒ¼:
 
-- reference/vector_cache/ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã™ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚
-- ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ•ã‚¡ã‚¤ãƒ« (reference/vector_cache/cache.json) ã‚’å‰Šé™¤ã—ã€å†ç”Ÿæˆã‚’è©¦ã¿ã¦ãã ã•ã„ã€‚
+- reference/vector_db/ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã™ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚
+- ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ•ã‚¡ã‚¤ãƒ« (reference/vector_db/cache.json) ã‚’å‰Šé™¤ã—ã€å†ç”Ÿæˆã‚’è©¦ã¿ã¦ãã ã•ã„ã€‚
 
 ãƒ¡ãƒ¢ãƒªã‚¨ãƒ©ãƒ¼:
 
@@ -615,7 +615,7 @@ GitHub Issues ã«ã¦å—ã‘ä»˜ã‘ã¦ã„ã¾ã™ã€‚ãƒã‚°å ±å‘Šã®éš›ã¯ã€ä»¥ä¸‹ã®
   - Lv1, Lv2, Lv3... ã®éšå±¤åˆ—ã«å¯¾å¿œ
 
 - **è¤‡æ•°ãƒ•ã‚©ãƒ«ãƒ€å¯¾å¿œ**
-  - `reference/ãƒãƒ¼ã‚¸ã‚·ãƒŠãƒªã‚ª/` ã¨ `reference/å±¥æ­´ãƒ‡ãƒ¼ã‚¿/` ã®çµ±åˆå‡¦ç†
+  - `reference/scenario/` ã¨ `reference/faq_data/` ã®çµ±åˆå‡¦ç†
   - å„ãƒ•ã‚©ãƒ«ãƒ€ã®æœ€æ–°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è‡ªå‹•é¸æŠ
   - 943ä»¶ã®å‚ç…§ãƒ‡ãƒ¼ã‚¿ã‚’çµ±åˆãƒ™ã‚¯ãƒˆãƒ«åŒ–
 
diff --git a/rag-gemini/requirements.txt b/rag-gemini/requirements.txt
index 5d642f7..0c935cd 100644
--- a/rag-gemini/requirements.txt
+++ b/rag-gemini/requirements.txt
@@ -3,11 +3,11 @@ numpy>=1.24.0
 sentence-transformers>=2.2.0
 scikit-learn>=1.3.0
 torch>=2.0.0
-# LangChainé–¢é€£ã‚’å‰Šé™¤ï¼ˆã‚¿ã‚°ãƒ¬ã‚¹å¯¾å¿œï¼‰
-# langchain>=0.1.0
-# langchain-anthropic>=0.0.1
-# langchain-openai>=0.0.1
-# langchain-google-genai>=0.0.1
+# LangChainé–¢é€£ï¼ˆLLMæ‹¡å¼µæ¤œç´¢æ©Ÿèƒ½ç”¨ï¼‰
+langchain>=0.1.0
+langchain-anthropic>=0.0.1
+langchain-openai>=0.0.1
+langchain-google-genai>=0.0.1
 google-generativeai>=0.3.0
 google-cloud-aiplatform>=1.35.0
 google-auth>=2.17.0
diff --git a/rag-gemini/src/handlers/input_handler.py b/rag-gemini/src/handlers/input_handler.py
index 52fcf96..2e256a4 100644
--- a/rag-gemini/src/handlers/input_handler.py
+++ b/rag-gemini/src/handlers/input_handler.py
@@ -57,7 +57,8 @@ class InputHandler:
 class ExcelInputHandler(InputHandler):
     def load_data(self) -> list:
         input_file = self._get_latest_file(self.input_dir, "*.xlsx")
-        logger.info(f"Processing input file: {os.path.basename(input_file)}")
+        self.current_file = os.path.basename(input_file)  # DBé¸æŠç”¨
+        logger.info(f"Processing input file: {self.current_file}")
         input_df = pd.read_excel(input_file)
 
         # åˆ—åãƒã‚§ãƒƒã‚¯ã¨ãƒ‡ãƒ¼ã‚¿æŠ½å‡º
@@ -314,11 +315,12 @@ class HierarchicalExcelInputHandler(InputHandler):
 
 class MultiFolderInputHandler(InputHandler):
     """è¤‡æ•°ãƒ•ã‚©ãƒ«ãƒ€ã‹ã‚‰å‚ç…§ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€ãƒãƒ³ãƒ‰ãƒ©ãƒ¼"""
-    
+
     def load_data(self) -> list:
         # å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ï¼ˆå¾“æ¥é€šã‚Šï¼‰
         input_file = self._get_latest_file(self.input_dir, "*.xlsx")
-        logger.info(f"Processing input file: {os.path.basename(input_file)}")
+        self.current_file = os.path.basename(input_file)  # DBé¸æŠç”¨
+        logger.info(f"Processing input file: {self.current_file}")
         input_df = pd.read_excel(input_file)
 
         # åˆ—åãƒã‚§ãƒƒã‚¯ã¨ãƒ‡ãƒ¼ã‚¿æŠ½å‡º
